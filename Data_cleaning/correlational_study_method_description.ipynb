{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlational Study Method Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-survey\n",
    "Participants will be asked about their demographic information, including age, gender, race, education level, and political affiliation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guilt task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants will be paired with a random partner for each trial. On each trial, the participant and the partner will see an array of dots (about 20) displayed on the screen for a short interval (1.5 s). The participant and, ostensibly, the partner indicate whether the number of the dots is larger or smaller than a reference number (e.g., 20). Afterward, their performance will be displayed on the screen. If one or both of them respond incorrectly, the partner has to watch an aversive image (i.e., unpleasant outcome) selected from the International Affective Picture System (IAPS). By manipulating the participant’s and the partner’s performance (i.e., correct/incorrect feedback), we are able to manipulate the participant’s responsibility in causing unpleasant outcomes to the partner (self-incorrect > both-incorrect > partner-incorrect). Unbeknownst to the participants, their and the partner’s performance feedback is predetermined. \n",
    "\n",
    "At the end of the trials where the partner had to watch the aversive picture, participants were prompted to answer one of following questions: (1) how guilty they were for the partner’s unpleasant outcome *(0-100 continuous scale)* and (2) how long they would be willing to watch the aversive picture themselves, which could reduce the time the partner had to watch the aversive picture (i.e., a measure of compensation) *(0-5 continuous scale)*; (3) the extent to which they were inclined to approach their partner for an apology or, conversely, to avoid interacting with them *(0-100 continuous scale)* (4) the likelihood of their partner forgiving them, as opposed to holding resentment towards them *(0-100 continuous scale)*. Each question was randomly presented *three times* in each condition (excluding the both-correct condition), and participants indicated their responses on analog scales.\n",
    "\n",
    "**Condition Randomization**\n",
    "There are *four* conditions (both-correct, self-incorrect, both-incorrect, partner-incorrect) and *four* dependent variables (guilt, share, approach/avoidance, forgive/mad). However, under both-correct condition, dependent variables will not be assess. Except both-correct condition, each type of trials has 3 repeats (4DV * 3 repeat = 12 trails for each condition), while both-correct condition has 4 repeats in total. The order of the trials is randomized for each participant. The number of dot in the stimuli and the position of response button are randomized accross participants.\n",
    "\n",
    "**Attention Check**\n",
    "To make sure participants are paying attention during the task, we included *two* attention check trials with apparent answers of the dot estimation task. Participants who fail to answer correctly will be warned to focus on the task. \\\n",
    "Participants have *5 seconds* to make judgement about the number of dots in each trial. If they fail to respond within the time limit, they will be warned to respond faster, while the trial will be marked as incomplete. After they complete the task, they will automatically move to an extra loop for the incomplete trials, which give them one more opportunity to respond to the incomplete trials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guilt data cleaning criteria\n",
    "Exclude:\n",
    "- acc < 0.8\n",
    "- complete less than 42 trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial trait task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stimuli**\n",
    "For the social judgment task, participants will see 50 neutral, frontal facial pictures sourced from three publicly available face databases (Chelnokova et al., 2014; DeBruine & Jones, 2017; Ma et al., 2015). To ensure a comprehensive representation of facial traits, we employed maximum variation sampling based on an independent set of facial rating data. Specifically, we selected 50 faces with the highest variation across the first four trait dimensions (Lin et al., 2021). This approach is aimed to maximize the diversity of facial features presented to participants, thereby ensuring representative and robust results. During the social trait judgment task, participants will evaluate **trustworthiness, friendliness, criticalness, and competence** of each face on a 1-7 continuous scale. We chose these specific traits on the warm/criticalness dimension of the facial trait space due to the significant association between perception of criticalness and guilt experience. Moreover, competence is included to incorporate the warmth-competence dimensions of trait judgments from faces, drawing from a well-established framework (Fiske et al., 2007). \n",
    "\n",
    "**Procedure**\n",
    "Participants will be instructed to evaluate each face on the four trait dimensions (trustworthiness, friendliness, criticalness, and competence) using a 1-7 continuous scale. The order of the trait dimensions will be randomized across participants to control for order effects. Each face will be presented for 0.5 seconds before the trait rating scale appears. There is no time limit for the trait rating, but participants will be encouraged to respond as quickly and accurately as possible, while swift (<0.2 seconds) and delayed (>10 seconds) response will be warned. The task will take approximately 10 minutes to complete. The task will take approximately 10 minutes to complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facial trait data cleaning criteria\n",
    "Exclude:\n",
    "- misses at least one section of trait rating\n",
    "- attention check accuracy < 0.8\n",
    "- exclude trails: response time > 10s or < 0.2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-survey\n",
    "After completing these two tasks, participants will undergo a battery of social anxiety assessments, including the Interaction and Audience Anxiousness Scales (Leary, 1983b), the Brief Fear of Negative Evaluation Scale (Leary, 1983a), and the Liebowitz Social Anxiety Scale (Liebowitz, 1987). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction and Audience Anxiousness Scales\n",
    "For each item, respondents are asked to indicate the \"degree to which the statement is characteristic of you\" on a 5-point scale ranging from 1 (not at all) to 5 (extremely characteristic).\n",
    "\n",
    "Reserve coding:\n",
    "- Interaction anxiousness: 3, 6, 10, 15\n",
    "- Audience anxiousness: 2, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIAS\n",
    "0-4 point (0=none, 4=extremely)\n",
    "\n",
    "20 items\n",
    "\n",
    "Reverse coding: 5, 9, 11\n",
    "\n",
    "### BFNE\n",
    "1-5 point (1=not at all, 5=extremely)\n",
    "\n",
    "12 items\n",
    "\n",
    "Reverse coding: 2, 4, 7, 10\n",
    "\n",
    "## liebowitz social anxiety scale\n",
    "two subscales: fear and avoidance\n",
    "\n",
    "both 24 social situations\n",
    "\n",
    "0-3 point (0=none, 3=severe)/(never-usually)\n",
    "\n",
    "Reverse coding: none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall description\n",
    "Time consumption: 40min - 1 hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Chelnokova, O., Laeng, B., Eikemo, M., Riegels, J., Løseth, G., Maurud, H., Willoch, F., & Leknes, S. (2014). Rewards of beauty: The opioid system mediates social motivation in humans. Molecular Psychiatry, 19(7), 746–747. https://doi.org/10.1038/mp.2014.1 \\\n",
    "DeBruine, L., & Jones, B. (2017). Face Research Lab London Set (p. 281699312 Bytes) [dataset]. [object Object]. https://doi.org/10.6084/M9.FIGSHARE.5047666.V3 \\\n",
    "Ma, D. S., Correll, J., & Wittenbrink, B. (2015). The Chicago face database: A free stimulus set of faces and norming data. Behavior Research Methods, 47(4), 1122–1135. https://doi.org/10.3758/s13428-014-0532-5"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
