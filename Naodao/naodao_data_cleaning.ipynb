{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean correlational study pilot data\n",
    "*Author*: Tianhao Qin\n",
    "\n",
    "*Date*: 03/28/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the data. Please check and make necessary changes according the folder structure on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tianh\\\\Desktop\\\\Naodao'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# define path\n",
    "scriptpath = os.path.abspath('') # path to this script\n",
    "\n",
    "# Go back twice to get the root path\n",
    "# rootpath = os.path.dirname(os.path.dirname(scriptpath))\n",
    "rootpath = scriptpath # In current setting, the working directory is the script's directory\n",
    "rootpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>RecipientLastName</th>\n",
       "      <th>...</th>\n",
       "      <th>liebowitz#2_19</th>\n",
       "      <th>liebowitz#2_20</th>\n",
       "      <th>liebowitz#2_21</th>\n",
       "      <th>liebowitz#2_22</th>\n",
       "      <th>liebowitz#2_23</th>\n",
       "      <th>liebowitz#2_24</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>status</th>\n",
       "      <th>naodao_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Start Date</td>\n",
       "      <td>End Date</td>\n",
       "      <td>Response Type</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>Progress</td>\n",
       "      <td>Duration (in seconds)</td>\n",
       "      <td>Finished</td>\n",
       "      <td>Recorded Date</td>\n",
       "      <td>Response ID</td>\n",
       "      <td>Recipient Last Name</td>\n",
       "      <td>...</td>\n",
       "      <td>下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...</td>\n",
       "      <td>下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...</td>\n",
       "      <td>下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...</td>\n",
       "      <td>下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...</td>\n",
       "      <td>下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...</td>\n",
       "      <td>下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...</td>\n",
       "      <td>您认为我们的研究是关于什么的？</td>\n",
       "      <td>为了帮助我们改进研究设置，您有什么意见或建议吗？</td>\n",
       "      <td>status</td>\n",
       "      <td>naodao_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"ImportId\":\"startDate\",\"timeZone\":\"America/Lo...</td>\n",
       "      <td>{\"ImportId\":\"endDate\",\"timeZone\":\"America/Los_...</td>\n",
       "      <td>{\"ImportId\":\"status\"}</td>\n",
       "      <td>{\"ImportId\":\"ipAddress\"}</td>\n",
       "      <td>{\"ImportId\":\"progress\"}</td>\n",
       "      <td>{\"ImportId\":\"duration\"}</td>\n",
       "      <td>{\"ImportId\":\"finished\"}</td>\n",
       "      <td>{\"ImportId\":\"recordedDate\",\"timeZone\":\"America...</td>\n",
       "      <td>{\"ImportId\":\"_recordId\"}</td>\n",
       "      <td>{\"ImportId\":\"recipientLastName\"}</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"ImportId\":\"QID10#2_114\"}</td>\n",
       "      <td>{\"ImportId\":\"QID10#2_115\"}</td>\n",
       "      <td>{\"ImportId\":\"QID10#2_116\"}</td>\n",
       "      <td>{\"ImportId\":\"QID10#2_117\"}</td>\n",
       "      <td>{\"ImportId\":\"QID10#2_118\"}</td>\n",
       "      <td>{\"ImportId\":\"QID10#2_119\"}</td>\n",
       "      <td>{\"ImportId\":\"QID13_TEXT\"}</td>\n",
       "      <td>{\"ImportId\":\"QID14_TEXT\"}</td>\n",
       "      <td>{\"ImportId\":\"QSEDstatus\"}</td>\n",
       "      <td>{\"ImportId\":\"naodao_id\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-13 20:09:46</td>\n",
       "      <td>2024-05-13 20:10:50</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>169.231.116.246</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-13 20:10:51</td>\n",
       "      <td>R_1fenaUBS3HK5kfc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>preview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-14 00:33:27</td>\n",
       "      <td>2024-05-14 00:33:59</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>169.231.116.172</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-14 00:34:00</td>\n",
       "      <td>R_6fkyD02y4BTGxfu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-14 00:40:41</td>\n",
       "      <td>2024-05-14 00:41:00</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>169.231.116.172</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-05-14 00:41:01</td>\n",
       "      <td>R_3etBmMxT3OmFCFt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>842788451870052353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           StartDate  \\\n",
       "0                                         Start Date   \n",
       "1  {\"ImportId\":\"startDate\",\"timeZone\":\"America/Lo...   \n",
       "2                                2024-05-13 20:09:46   \n",
       "3                                2024-05-14 00:33:27   \n",
       "4                                2024-05-14 00:40:41   \n",
       "\n",
       "                                             EndDate                 Status  \\\n",
       "0                                           End Date          Response Type   \n",
       "1  {\"ImportId\":\"endDate\",\"timeZone\":\"America/Los_...  {\"ImportId\":\"status\"}   \n",
       "2                                2024-05-13 20:10:50             IP Address   \n",
       "3                                2024-05-14 00:33:59             IP Address   \n",
       "4                                2024-05-14 00:41:00             IP Address   \n",
       "\n",
       "                  IPAddress                 Progress    Duration (in seconds)  \\\n",
       "0                IP Address                 Progress    Duration (in seconds)   \n",
       "1  {\"ImportId\":\"ipAddress\"}  {\"ImportId\":\"progress\"}  {\"ImportId\":\"duration\"}   \n",
       "2           169.231.116.246                      100                       64   \n",
       "3           169.231.116.172                      100                       32   \n",
       "4           169.231.116.172                      100                       19   \n",
       "\n",
       "                  Finished                                       RecordedDate  \\\n",
       "0                 Finished                                      Recorded Date   \n",
       "1  {\"ImportId\":\"finished\"}  {\"ImportId\":\"recordedDate\",\"timeZone\":\"America...   \n",
       "2                     True                                2024-05-13 20:10:51   \n",
       "3                     True                                2024-05-14 00:34:00   \n",
       "4                     True                                2024-05-14 00:41:01   \n",
       "\n",
       "                 ResponseId                 RecipientLastName  ...  \\\n",
       "0               Response ID               Recipient Last Name  ...   \n",
       "1  {\"ImportId\":\"_recordId\"}  {\"ImportId\":\"recipientLastName\"}  ...   \n",
       "2         R_1fenaUBS3HK5kfc                               NaN  ...   \n",
       "3         R_6fkyD02y4BTGxfu                               NaN  ...   \n",
       "4         R_3etBmMxT3OmFCFt                               NaN  ...   \n",
       "\n",
       "                                      liebowitz#2_19  \\\n",
       "0  下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...   \n",
       "1                         {\"ImportId\":\"QID10#2_114\"}   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                      liebowitz#2_20  \\\n",
       "0  下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...   \n",
       "1                         {\"ImportId\":\"QID10#2_115\"}   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                      liebowitz#2_21  \\\n",
       "0  下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...   \n",
       "1                         {\"ImportId\":\"QID10#2_116\"}   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                      liebowitz#2_22  \\\n",
       "0  下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...   \n",
       "1                         {\"ImportId\":\"QID10#2_117\"}   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                      liebowitz#2_23  \\\n",
       "0  下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...   \n",
       "1                         {\"ImportId\":\"QID10#2_118\"}   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                      liebowitz#2_24  \\\n",
       "0  下面这个量表会测量不同情景下社交焦虑对你生活的影响。请仔细阅读每种情况，并回答两个问题：第一...   \n",
       "1                         {\"ImportId\":\"QID10#2_119\"}   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                         Q10                        Q11  \\\n",
       "0            您认为我们的研究是关于什么的？   为了帮助我们改进研究设置，您有什么意见或建议吗？   \n",
       "1  {\"ImportId\":\"QID13_TEXT\"}  {\"ImportId\":\"QID14_TEXT\"}   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "                      status                 naodao_id  \n",
       "0                     status                 naodao_id  \n",
       "1  {\"ImportId\":\"QSEDstatus\"}  {\"ImportId\":\"naodao_id\"}  \n",
       "2                          1                   preview  \n",
       "3                          1                       NaN  \n",
       "4                          1        842788451870052353  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# guilt\n",
    "filename_pattern = re.compile(r'.*interactive game.*Psychopy.csv')\n",
    "dfs_guilt = []\n",
    "filename_guilt = [f for f in glob.glob(os.path.join(rootpath, 'data', '*')) if filename_pattern.match(f)]\n",
    "# read in the data according to the filename\n",
    "for f in filename_guilt:\n",
    "    try:\n",
    "        dfs_guilt.append(pd.read_csv(f))\n",
    "    except:\n",
    "        print(f\"Error occur when loading:{f}\")\n",
    "\n",
    "# trait\n",
    "dfs_trait = []\n",
    "filename_pattern = re.compile(r'.*judgment task.*Psychopy.csv')\n",
    "filename_trait = [f for f in glob.glob(os.path.join(rootpath, 'data', '*')) if filename_pattern.match(f)]\n",
    "for f in filename_trait:\n",
    "    try:\n",
    "        dfs_trait.append(pd.read_csv(f))\n",
    "    except:\n",
    "        print(f\"Error occur when loading:{f}\")\n",
    "\n",
    "# show\n",
    "post_survey.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participants in guilt: 19, participant in trait: 19\n"
     ]
    }
   ],
   "source": [
    "print(f\"participants in guilt: {len(filename_guilt)}, participant in trait: {len(filename_trait)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_col(df, colname_pattern):\n",
    "    \"\"\"\n",
    "    Extract columns with the specified pattern from the DataFrame\n",
    "    \"\"\"\n",
    "    # Filter columns based on the specified patterns\n",
    "    columns_to_select = [col for col in df.columns if any(pattern in col for pattern in colname_pattern)]\n",
    "\n",
    "    # Create the anxiety DataFrame\n",
    "    df_out = df[columns_to_select]\n",
    "\n",
    "    # if df_out.shape[1] < colname_pattern.__len__():\n",
    "    #     print(f\"Warning: Not all columns with the pattern {colname_pattern} are found in the DataFrame\")\n",
    "\n",
    "    # Remove rows where participantID is NaN\n",
    "    if 'participantID' in df_out.columns:\n",
    "        df_out = df_out.dropna(subset=['participantID'])\n",
    "    elif 'naodao_id' in df_out.columns:\n",
    "        df_out = df_out.dropna(subset=['naodao_id'])\n",
    "    elif 'participant' in df_out.columns and df_out.shape[1] < colname_pattern.__len__():\n",
    "        print(f\"{df_out['participant'][0]} has missing columns\")\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_survey = pd.read_csv(glob.glob(os.path.join(rootpath, 'data', 'SAD_presurvey_CN_June 3, 2024_09.29.csv'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_survey_clean = extract_col(pre_survey, \n",
    "                               ['ResponseID', 'naodao_id', 'Gender', 'Gender_5_TEXT', 'Q6', 'Q7', 'Q7_2_TEXT', \n",
    "                                'Q9'])\n",
    "# pre_survey_clean\n",
    "\n",
    "pre_survey_clean = pre_survey_clean.drop([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gender Gender_5_TEXT   Q6   Q7 Q7_2_TEXT   Q9           naodao_id\n",
      "5     女性           NaN  NaN  NaN       NaN  NaN             preview\n",
      "6    NaN           NaN  NaN  NaN       NaN  NaN  842721462082215938\n",
      "7    NaN           NaN  NaN  NaN       NaN  NaN  842721462082215938\n",
      "8    NaN           NaN  NaN  NaN       NaN  NaN  842721462082215938\n",
      "9    NaN           NaN  NaN  NaN       NaN  NaN  842780936444841985\n"
     ]
    }
   ],
   "source": [
    "# Check if the DataFrame looks correct\n",
    "print(pre_survey_clean.head())\n",
    "\n",
    "# If the DataFrame is correct and you want to standardize the encoding to UTF-8\n",
    "pre_survey_clean.to_csv('data/revised_presurvey'+date+'.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "post_survey = pd.read_csv(glob.glob(os.path.join(rootpath, 'data', 'SAD_Post_Questionnaire_CN_June 3, 2024_09.30.csv'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_survey_clean = extract_col(post_survey,\n",
    "                                ['naodao_ID', \n",
    "                                 'SIAS', 'Interaction', 'Audience', 'neg_eva', 'liebowitz'])\n",
    "\n",
    "# remove the first and second rows\n",
    "post_survey_clean = post_survey_clean.drop([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try opening the file with different encodings if you're unsure\n",
    "try:\n",
    "    # Attempt to read with UTF-8 encoding\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    # If UTF-8 fails, try another encoding, like GBK for Simplified Chinese\n",
    "    df = pd.read_csv(file_path, encoding='gbk')\n",
    "\n",
    "# Check if the DataFrame looks correct\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_survey_clean.to_csv('data/revised_postsurvey'+date+'.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate scores for each scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Que_scores(df, scaleprefix, reverse_coding, rating_scale):\n",
    "    # input: df by subjects * items\n",
    "    # output: total score for each subject\n",
    "    if scaleprefix == 'liebowitz_fear':\n",
    "        scaleprefix = 'liebowitz#1'\n",
    "    elif scaleprefix == 'liebowitz_avoidance':\n",
    "        scaleprefix = 'liebowitz#2'\n",
    "    # get columns accroding to the prefix\n",
    "    cols = [col for col in df.columns if scaleprefix in col]\n",
    "    df_scale = df[cols]\n",
    "    df_scale_r = pd.DataFrame()\n",
    "    for col in df_scale.columns:\n",
    "        # creat $temp$ as a new integer column\n",
    "        # if the first character is not a number, it will be converted to NaN\n",
    "        temp = pd.to_numeric(df_scale[col].str[0], errors='coerce')\n",
    "        # print(temp)\n",
    "\n",
    "        # if this column need to be reverse coded\n",
    "        if col.split('_')[-1] in reverse_coding:\n",
    "            df_scale_r[col] = rating_scale[1] - temp + rating_scale[0]\n",
    "        else:\n",
    "            df_scale_r[col] = temp\n",
    "    # calculate the total score for each subject, ignoring NaN\n",
    "    total_score = df_scale_r.mean(axis=1 ,skipna=True)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'participantID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'participantID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     df_qscores[prefix] \u001b[38;5;241m=\u001b[39m Que_scores(post_survey_clean, prefix, reverse_coding[prefix], rating_scale[prefix])\n\u001b[0;32m     19\u001b[0m df_qscores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliebowitz_total\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df_qscores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliebowitz_fear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m df_qscores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliebowitz_avoidance\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 20\u001b[0m df_qscores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparticipantID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpost_survey_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparticipantID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# for each participant, if there are more than one scores missing, remove this participant\u001b[39;00m\n\u001b[0;32m     23\u001b[0m df_qscores \u001b[38;5;241m=\u001b[39m df_qscores\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'participantID'"
     ]
    }
   ],
   "source": [
    "scaleprefix = ['SIAS', 'Interaction', 'Audience', 'neg_eva', 'liebowitz_fear', 'liebowitz_avoidance']\n",
    "# you can see the reverse coding information in [doc](correlational_study_method_description.ipynb)\n",
    "reverse_coding = {'SIAS': ['5', '9', '11'], \n",
    "                 'Interaction': ['3', '6', '10', '15'], \n",
    "                 'Audience': ['2', '8'],\n",
    "                 'neg_eva': ['2', '4', '7', '10'],\n",
    "                 'liebowitz_fear': [], 'liebowitz_avoidance': []}\n",
    "rating_scale = {\n",
    "    'SIAS': [0, 4],\n",
    "    'Interaction': [1,5],\n",
    "    'Audience': [1,5],\n",
    "    'neg_eva': [1,5],\n",
    "    'liebowitz_fear': [0,3],\n",
    "    'liebowitz_avoidance': [0,3]\n",
    "}\n",
    "df_qscores = pd.DataFrame()\n",
    "for prefix in scaleprefix:\n",
    "    df_qscores[prefix] = Que_scores(post_survey_clean, prefix, reverse_coding[prefix], rating_scale[prefix])\n",
    "df_qscores['liebowitz_total'] = (df_qscores['liebowitz_fear'] + df_qscores['liebowitz_avoidance'])/2\n",
    "df_qscores['participantID'] = post_survey_clean['participantID']\n",
    "\n",
    "# for each participant, if there are more than one scores missing, remove this participant\n",
    "df_qscores = df_qscores.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 7)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qscores.head()\n",
    "df_qscores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guilt task\n",
    "### Long format\n",
    "This step select columns in interests, and excluded those do not have all DVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_col(df, colname_pattern):\n",
    "    \"\"\"\n",
    "    Extract columns with the specified pattern from the DataFrame\n",
    "    \"\"\"\n",
    "    # Filter columns based on the specified patterns\n",
    "    columns_to_select = [col for col in df.columns if any(pattern in col for pattern in colname_pattern)]\n",
    "\n",
    "    # Create the anxiety DataFrame\n",
    "    df_out = df[columns_to_select]\n",
    "\n",
    "    # if df_out.shape[1] < colname_pattern.__len__():\n",
    "    #     print(f\"Warning: Not all columns with the pattern {colname_pattern} are found in the DataFrame\")\n",
    "\n",
    "    # Remove rows where participantID is NaN\n",
    "    if 'participantID' in df_out.columns:\n",
    "        df_out = df_out.dropna(subset=['participantID'])\n",
    "    elif 'participant' in df_out.columns and df_out.shape[1] < colname_pattern.__len__():\n",
    "        print(f\"{df_out['participant'][0]} has missing columns\")\n",
    "\n",
    "    return df_out\n",
    "\n",
    "# Define the patterns to search for\n",
    "DVname = ['slider_guilt', 'share_slider', 'slider_apology', \\\n",
    "          'slider_hide', 'slider_forgiveness', 'slider_mad']\n",
    "\n",
    "# Filter columns based on the specified patterns\n",
    "subject_info = ['participant', 'date', 'chooserow', \\\n",
    "                     'stipic', 'type_trial', 'DV', \\\n",
    "                     'judge.clicked_name','answer', 'incompleteTrials']\n",
    "\n",
    "dfs_guilt_clean = []\n",
    "for df in dfs_guilt:\n",
    "    df_cleaned = extract_col(df, DVname + subject_info)\n",
    "    \n",
    "    # print(f\"number of trials: {df_cleaned['chooserow'][0].__len__()}\")\n",
    "    # print(f\"shape: {df_cleaned.shape}\")\n",
    "\n",
    "    try:\n",
    "        if df_cleaned.shape[1] > 18 and df_cleaned.shape[0] > 41: # they should have a total of 42 trials at least\n",
    "            dfs_guilt_clean.append(df_cleaned)\n",
    "            # dfs_guilt_clean.loc[len(dfs_guilt_clean)+1,:]\n",
    "        else:\n",
    "            print(f\"{df_cleaned['participant'][0]} completed less than 42 trials\")\n",
    "    except:\n",
    "        print(f\"Error: {df_cleaned['date'][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw2long(df, \n",
    "              keep_columns = [], \n",
    "              DVname = [], \n",
    "              have_attention_check = False, check_missing = False, \n",
    "              drop_according = ''):\n",
    "    \"\"\"\n",
    "    Convert the DataFrame from wide to long format\n",
    "    \"\"\"\n",
    "    # print(f\"Participant {df['participant'][0]}\")\n",
    "\n",
    "    # if a column is missing according to keep_columns, add it\n",
    "    for col in keep_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "    # return df\n",
    "    \n",
    "    selectrow = df[keep_columns + [col + '.response' for col in DVname] + [col + '.rt' for col in DVname]]\n",
    "    # print(selectrow.columns)\n",
    "\n",
    "    # for guilt task, calculate accuracy in attention check\n",
    "    # attention check: compare judge.clicked_name and answer if answer is not 'No answer'\n",
    "    if have_attention_check:\n",
    "        attention_check = selectrow.dropna(subset=['answer']).query(\"answer == 'RightButton' or answer == 'LeftButton'\")\n",
    "        acc = np.mean(attention_check['judge.clicked_name'] == attention_check['answer'])\n",
    "        if acc > 0.8:\n",
    "            print(f\"Participant {selectrow['participant'][0]} acc = {acc}\")\n",
    "        else:\n",
    "            print(f\"Participant {selectrow['participant'][0]} acc = {acc} < 0.8 *****\")\n",
    "            return None # remove this participant\n",
    "    \n",
    "    if check_missing:\n",
    "        missed_trials = selectrow['incompleteTrials'].dropna().values\n",
    "        if len(missed_trials)>0:\n",
    "            print(f\"    Missed trials: {missed_trials}\")\n",
    "\n",
    "    # # Melt the DataFrame to convert it to long format\n",
    "    df_long = pd.melt(selectrow, \n",
    "                    id_vars=keep_columns, \n",
    "                    value_vars=[col + '.response' for col in DVname] + [col + '.rt' for col in DVname],\n",
    "                    var_name='DV_type',\n",
    "                    value_name='DV_value')\n",
    "\n",
    "    # Extract DV from DV_type\n",
    "    df_long['DV_name'] = df_long['DV_type'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "    # Extract rt or response from DV_type\n",
    "    df_long['DV_resptype'] = df_long['DV_type'].apply(lambda x: 'rt' if 'rt' in x else 'response')\n",
    "\n",
    "    # clean for non stimuli\n",
    "    # print(drop_according)\n",
    "    df_long = df_long.dropna(subset=[drop_according])\n",
    "\n",
    "    return df_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant er3 acc = 1.0\n",
      "    Missed trials: [ 59. 163. 176.]\n",
      "Participant sppq acc = 0.0 < 0.8 *****\n",
      "Participant 一 一 acc = 0.5 < 0.8 *****\n",
      "Participant 加多宝 acc = 1.0\n",
      "    Missed trials: [179.]\n",
      "Participant 土豆洋芋薯片 acc = 1.0\n",
      "Participant 好运跟着来呗 acc = 1.0\n",
      "    Missed trials: [90.]\n",
      "Participant 守护 acc = 1.0\n",
      "Participant 快乐修勾 acc = 1.0\n",
      "Participant 我努力赚钱 acc = 1.0\n",
      "Participant 挽冬 acc = 1.0\n",
      "Participant 爱购i acc = 1.0\n",
      "Participant 王子鸣 acc = 1.0\n",
      "    Missed trials: [59.]\n",
      "Participant 用户30686 acc = 1.0\n",
      "Participant 用户41526 acc = 1.0\n",
      "Participant 山鬼丫 acc = 1.0\n",
      "Participant 用户7465 acc = 1.0\n",
      "Participant 笙笙 acc = 0.5 < 0.8 *****\n",
      "Participant 繁星点点 acc = 1.0\n",
      "Participant 这是一个小天才 acc = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n",
      "C:\\Users\\tianh\\AppData\\Local\\Temp\\ipykernel_48516\\3066940952.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = np.nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# start converting to long format\n",
    "dfs_guilt_long = []\n",
    "for df in dfs_guilt_clean:\n",
    "    dftolong = raw2long(df, \n",
    "                        keep_columns=subject_info,\n",
    "                        DVname=DVname,\n",
    "                        have_attention_check = True, \n",
    "                        check_missing = True, \n",
    "                        drop_according='stipic')\n",
    "    # check if the return is None\n",
    "    if dftolong is not None:\n",
    "        dfs_guilt_long.append(dftolong)\n",
    "    # print(f\"Participant {df['participant'][0]}\")\n",
    "\n",
    "# dfs_guilt_long.__len__() # 8 valid participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant er3 acc = 1.0\n",
      "    Missed trials: [ 59. 163. 176.]\n",
      "Participant sppq acc = 0.0 < 0.8 *****\n",
      "Participant 一 一 acc = 0.5 < 0.8 *****\n",
      "Participant 加多宝 acc = 1.0\n",
      "    Missed trials: [179.]\n",
      "Participant 土豆洋芋薯片 acc = 1.0\n",
      "Participant 好运跟着来呗 acc = 1.0\n",
      "    Missed trials: [90.]\n",
      "Participant 守护 acc = 1.0\n",
      "Participant 快乐修勾 acc = 1.0\n",
      "Participant 我努力赚钱 acc = 1.0\n",
      "Participant 挽冬 acc = 1.0\n",
      "Participant 爱购i acc = 1.0\n",
      "Participant 王子鸣 acc = 1.0\n",
      "    Missed trials: [59.]\n",
      "Participant 用户30686 acc = 1.0\n",
      "Participant 用户41526 acc = 1.0\n",
      "Participant 山鬼丫 acc = 1.0\n",
      "Participant 用户7465 acc = 1.0\n",
      "Participant 笙笙 acc = 0.5 < 0.8 *****\n",
      "Participant 繁星点点 acc = 1.0\n",
      "Participant 这是一个小天才 acc = 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# start converting to long format\n",
    "dfs_guilt_long = []\n",
    "for df in dfs_guilt_clean:\n",
    "    dftolong = raw2long(df, \n",
    "                        keep_columns=subject_info,\n",
    "                        DVname=DVname,\n",
    "                        have_attention_check = True, \n",
    "                        check_missing = True, \n",
    "                        drop_according='stipic')\n",
    "    # check if the return is None\n",
    "    if dftolong is not None:\n",
    "        dfs_guilt_long.append(dftolong)\n",
    "    # print(f\"Participant {df['participant'][0]}\")\n",
    "\n",
    "# dfs_guilt_long.__len__() # 8 valid participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 16 participants in guilt task\n"
     ]
    }
   ],
   "source": [
    "# check guilt participants\n",
    "print(f\"Now we have {len(dfs_guilt_long)} participants in guilt task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guilt: wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long2wide(df_long, DVtype):\n",
    "    \"\"\"\n",
    "    convert long format data to wide format\n",
    "    \"\"\"\n",
    "    # Filter rows with non-NA values and specific trial type and DV type\n",
    "    thisDVtype = DVtype + '.response'\n",
    "    filtered_df = df_long.dropna(subset=['DV_value']).query(\"(type_trial == 1 and DV_type == @thisDVtype) or (type_trial == 3 and DV_type == @thisDVtype)\")\n",
    "    \n",
    "    # Calculate the mean value across rows\n",
    "    mean_value = filtered_df.groupby('type_trial')['DV_value'].mean().reset_index()\n",
    "    diff_value = mean_value.loc[mean_value['type_trial'] == 3]['DV_value'].values[0] - mean_value.loc[mean_value['type_trial'] == 1]['DV_value'].values[0]\n",
    "    # diff_value = mean_value.loc['type_trial'==3]['DV_value'] - mean_value.loc['type_trial' == 1]['DV_value']\n",
    "    # change 'DV_value' to thisDVtype\n",
    "    # diff_value = diff_value.rename(columns={'DV_value': thisDVtype.split('.')[0]+'_diff'})\n",
    "\n",
    "    result = {DVtype+'_both_incor': mean_value.loc[mean_value['type_trial'] == 1]['DV_value'].values[0],\n",
    "              DVtype+'_self_incor': mean_value.loc[mean_value['type_trial'] == 3]['DV_value'].values[0],\n",
    "              DVtype+'_diff': diff_value}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = pd.DataFrame()\n",
    "\n",
    "for df in dfs_guilt_long:\n",
    "    this_df = pd.DataFrame()\n",
    "\n",
    "    # save subject_info\n",
    "    thisSubInfo = df[['participant']].iloc[0]\n",
    "    # temp = thisSubInfo['participant']\n",
    "    this_df.loc[0, 'participant'] = thisSubInfo['participant']\n",
    "    # print(this_df)\n",
    "\n",
    "    for DVtype in DVname:\n",
    "        dv_diff = long2wide(df, DVtype= DVtype)\n",
    "        # dv_name = DVtype + '_diff'\n",
    "        # this_df.loc[0, dv_name] = dv_diff\n",
    "        # this_df = pd.merge(this_df, this_dv_df, on=['type_trial'], how='outer')\n",
    "        for key, value in dv_diff.items():\n",
    "            this_df.loc[0, key] = value\n",
    "    \n",
    "    # print(this_df)\n",
    "\n",
    "    # put into a large df\n",
    "    df_wide = pd.concat([df_wide, this_df], axis=0)\n",
    "\n",
    "# df_wide['condition'] = df_wide['type_trial'].apply(lambda x: 'both_incor' if x == 1 else 'self_incor')\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 19)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide.head()\n",
    "df_wide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# get the current date\n",
    "date = time.strftime(\"%m-%d\", time.localtime())\n",
    "date\n",
    "\n",
    "# create a directory to save the data\n",
    "savepath = os.path.join(rootpath, 'result')\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "# guilt\n",
    "# encoding='utf_8_sig' is to ensure that the Chinese characters will be saved properly\n",
    "df_wide.to_csv(savepath+'/naodao_guilt_task_wide_'+date+'.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial trait task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw2long_trait(df, \n",
    "                   keep_columns=[],\n",
    "                   DVname=[], \n",
    "                   have_attention_check=False, \n",
    "                   check_missing=False, \n",
    "                   drop_according=''):\n",
    "    \"\"\"\n",
    "    Convert the DataFrame from wide to long format\n",
    "    \"\"\"\n",
    "    # select columns\n",
    "    colinterest = keep_columns + [col + '.response' for col in DVname] + [col + '.rt' for col in DVname]\n",
    "    for col in colinterest:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "    selectrow = df[colinterest]\n",
    "\n",
    "    if have_attention_check:\n",
    "        attention_check = selectrow.dropna(subset=['isCheck']).query(\"isCheck == 1\")\n",
    "        if attention_check['answer'].notnull().any():\n",
    "            # in one version of this experiment, the answer is a random number\n",
    "            acc = np.mean(np.logical_and(attention_check['slider_face_judge.response'] > attention_check['answer']-0.5,\n",
    "                                         attention_check['slider_face_judge.response'] < attention_check['answer']+0.5))\n",
    "        elif attention_check['isCheck'].notnull().any():\n",
    "            # in one version of this experiment, we set the answer as 5\n",
    "            acc = np.mean(np.logical_and(attention_check['slider_face_judge.response'] > 5-0.5,\n",
    "                                         attention_check['slider_face_judge.response'] < 5+0.5))\n",
    "        else:\n",
    "            # in the early version of this experiment, there's no attention check\n",
    "            acc = None\n",
    "\n",
    "        if acc is None or acc < 0.8:\n",
    "            if not selectrow.empty and 'participant' in selectrow.columns:\n",
    "                print(f\"Participant {selectrow['participant'].iloc[0]} acc = {acc} < 0.8 *****\")\n",
    "            df_long = []\n",
    "            return df_long   \n",
    "\n",
    "    session_trait = []\n",
    "    if check_missing:\n",
    "        if selectrow['slider_judge_img'].notnull().any():\n",
    "            session_trait = [x for x in selectrow['slider_judge_img'].unique() if x is not np.nan]\n",
    "\n",
    "    if len(session_trait) > 3: \n",
    "        if selectrow['isCheck'].notnull().any():\n",
    "            df_long = selectrow.dropna(subset=[drop_according]).query('isCheck==0')\n",
    "        else:\n",
    "            df_long = selectrow.dropna(subset=[drop_according])\n",
    "        \n",
    "        if df_long.shape[0] == 200:\n",
    "            df_long.loc[:49, 'slider_judge_img'] = session_trait[0]\n",
    "            df_long.loc[50:99, 'slider_judge_img'] = session_trait[1]\n",
    "            df_long.loc[100:149, 'slider_judge_img'] = session_trait[2]\n",
    "            df_long.loc[150:, 'slider_judge_img'] = session_trait[3]\n",
    "            df_long = df_long.dropna(subset=['slider_face_judge.response'])\n",
    "            df_long = df_long.query('`slider_face_judge.rt` > 0.2 and `slider_face_judge.rt` < 10')\n",
    "        else:\n",
    "            print(f\"Participant {df_long['participant'].iloc[0]} has less than 200 trials\")\n",
    "            df_long = []\n",
    "    else:\n",
    "        df_long = []\n",
    "\n",
    "    return df_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_info = ['participant', 'face_serial', 'isCheck', 'answer', \\\n",
    "            'session_serial', 'slider_judge_img', 'image_name']\n",
    "exp_info = ['slider_face_judge']\n",
    "\n",
    "df_long = raw2long_trait(dfs_trait[0], \n",
    "                        keep_columns=sub_info,\n",
    "                        DVname = exp_info,\n",
    "                        have_attention_check = True, \n",
    "                        check_missing = True, \n",
    "                        drop_according='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_info = ['participant', 'face_serial', 'isCheck', 'answer', \\\n",
    "            'session_serial', 'slider_judge_img', 'image_name']\n",
    "exp_info = ['slider_face_judge']\n",
    "\n",
    "# facial trait task\n",
    "dfs_long = pd.DataFrame()\n",
    "for df in dfs_trait:\n",
    "    # Now we don't exlude any participants according to their performance in attention check\n",
    "    df_long = raw2long_trait(df, \n",
    "                             keep_columns=sub_info,\n",
    "                             DVname = exp_info,\n",
    "                             have_attention_check = False, \n",
    "                             check_missing = True, \n",
    "                             drop_according='image_name')\n",
    "    if len(df_long) > 0:\n",
    "        # Append the new observation using pd.concat\n",
    "        dfs_long = pd.concat([dfs_long, df_long], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>face_serial</th>\n",
       "      <th>isCheck</th>\n",
       "      <th>answer</th>\n",
       "      <th>session_serial</th>\n",
       "      <th>slider_judge_img</th>\n",
       "      <th>image_name</th>\n",
       "      <th>slider_face_judge.response</th>\n",
       "      <th>slider_face_judge.rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>er3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>friendly.png</td>\n",
       "      <td>image/49.jpg</td>\n",
       "      <td>6.037500</td>\n",
       "      <td>1.8030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>er3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>friendly.png</td>\n",
       "      <td>image/47.jpg</td>\n",
       "      <td>3.968750</td>\n",
       "      <td>2.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>er3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>friendly.png</td>\n",
       "      <td>image/29.jpg</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>2.5130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>er3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>friendly.png</td>\n",
       "      <td>image/19.jpg</td>\n",
       "      <td>2.043750</td>\n",
       "      <td>1.9110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>er3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>friendly.png</td>\n",
       "      <td>image/50.jpg</td>\n",
       "      <td>5.975000</td>\n",
       "      <td>4.0520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>这是一个小天才</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trustworthy.png</td>\n",
       "      <td>image/22.jpg</td>\n",
       "      <td>5.427778</td>\n",
       "      <td>2.5034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>这是一个小天才</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trustworthy.png</td>\n",
       "      <td>image/48.jpg</td>\n",
       "      <td>4.538889</td>\n",
       "      <td>1.4899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>这是一个小天才</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trustworthy.png</td>\n",
       "      <td>image/37.jpg</td>\n",
       "      <td>5.094445</td>\n",
       "      <td>1.4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>这是一个小天才</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trustworthy.png</td>\n",
       "      <td>image/50.jpg</td>\n",
       "      <td>4.005555</td>\n",
       "      <td>1.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>这是一个小天才</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trustworthy.png</td>\n",
       "      <td>image/36.jpg</td>\n",
       "      <td>4.427778</td>\n",
       "      <td>1.8551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3796 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant  face_serial  isCheck  answer  session_serial  \\\n",
       "0            er3         49.0      0.0     0.0             NaN   \n",
       "1            er3         47.0      0.0     0.0             NaN   \n",
       "2            er3         29.0      0.0     0.0             NaN   \n",
       "3            er3         19.0      0.0     0.0             NaN   \n",
       "4            er3         50.0      0.0     0.0             NaN   \n",
       "...          ...          ...      ...     ...             ...   \n",
       "3791     这是一个小天才         22.0      0.0     0.0             NaN   \n",
       "3792     这是一个小天才         48.0      0.0     0.0             NaN   \n",
       "3793     这是一个小天才         37.0      0.0     0.0             NaN   \n",
       "3794     这是一个小天才         50.0      0.0     0.0             NaN   \n",
       "3795     这是一个小天才         36.0      0.0     0.0             NaN   \n",
       "\n",
       "     slider_judge_img    image_name  slider_face_judge.response  \\\n",
       "0        friendly.png  image/49.jpg                    6.037500   \n",
       "1        friendly.png  image/47.jpg                    3.968750   \n",
       "2        friendly.png  image/29.jpg                    1.950000   \n",
       "3        friendly.png  image/19.jpg                    2.043750   \n",
       "4        friendly.png  image/50.jpg                    5.975000   \n",
       "...               ...           ...                         ...   \n",
       "3791  trustworthy.png  image/22.jpg                    5.427778   \n",
       "3792  trustworthy.png  image/48.jpg                    4.538889   \n",
       "3793  trustworthy.png  image/37.jpg                    5.094445   \n",
       "3794  trustworthy.png  image/50.jpg                    4.005555   \n",
       "3795  trustworthy.png  image/36.jpg                    4.427778   \n",
       "\n",
       "      slider_face_judge.rt  \n",
       "0                   1.8030  \n",
       "1                   2.0330  \n",
       "2                   2.5130  \n",
       "3                   1.9110  \n",
       "4                   4.0520  \n",
       "...                    ...  \n",
       "3791                2.5034  \n",
       "3792                1.4899  \n",
       "3793                1.4350  \n",
       "3794                1.8460  \n",
       "3795                1.8551  \n",
       "\n",
       "[3796 rows x 9 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants in facial trait task: 55\n"
     ]
    }
   ],
   "source": [
    "# dfs_long['participant'].unique().__len__()\n",
    "print(f\"Number of participants in facial trait task: {dfs_long['participant'].unique().__len__()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long2wide_trait(df_long):\n",
    "    # drop non response rows\n",
    "    # df_long = df_long.dropna(subset=['slider_face_judge.response'])\n",
    "    df_long.loc[:, 'trait'] = df_long['slider_judge_img'].apply(lambda x: x.split('.')[0])\n",
    "    # calcualte the mean value for each trait\n",
    "    df_long_mean = df_long.groupby(['participant', 'trait'])['slider_face_judge.response'].mean().reset_index()\n",
    "\n",
    "    # convert long format data to wide format for facial trait task and calculate the mean value for each trait\n",
    "    df_wide = df_long_mean.pivot(index='participant', \n",
    "                            columns='trait', \n",
    "                            values='slider_face_judge.response').reset_index()\n",
    "    # print(df_wide.head(5))\n",
    "\n",
    "    return df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_trait = long2wide_trait(dfs_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>trait</th>\n",
       "      <th>participant</th>\n",
       "      <th>competent</th>\n",
       "      <th>critical</th>\n",
       "      <th>friendly</th>\n",
       "      <th>trustworthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>挽冬</td>\n",
       "      <td>3.790189</td>\n",
       "      <td>4.187077</td>\n",
       "      <td>3.843716</td>\n",
       "      <td>4.234904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>er3</td>\n",
       "      <td>3.514583</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.345213</td>\n",
       "      <td>3.914139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sppq</td>\n",
       "      <td>4.027259</td>\n",
       "      <td>3.708899</td>\n",
       "      <td>3.575663</td>\n",
       "      <td>3.802729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>一 一</td>\n",
       "      <td>4.124445</td>\n",
       "      <td>4.289480</td>\n",
       "      <td>3.666549</td>\n",
       "      <td>4.082971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>加多宝</td>\n",
       "      <td>3.254972</td>\n",
       "      <td>4.662478</td>\n",
       "      <td>2.795782</td>\n",
       "      <td>2.786244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "trait participant  competent  critical  friendly  trustworthy\n",
       "0              挽冬   3.790189  4.187077  3.843716     4.234904\n",
       "1             er3   3.514583  3.500000  3.345213     3.914139\n",
       "2            sppq   4.027259  3.708899  3.575663     3.802729\n",
       "3             一 一   4.124445  4.289480  3.666549     4.082971\n",
       "4             加多宝   3.254972  4.662478  2.795782     2.786244"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide_trait.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trait\n",
    "df_wide_trait.to_csv(savepath+'/naodao_trait_task_wide_'+date+'.csv', index=False, encoding='utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
